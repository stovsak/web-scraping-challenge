{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to choose the executable path to driver\n",
    "def init_browser():\n",
    "    executable_path = {\"executable_path\": \"C:/chromedriver/chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Scrape function.\n",
    "def scrape():\n",
    "\n",
    "\n",
    "    \"\"\" NASA Mars News \"\"\"\n",
    "\n",
    "\n",
    "    # Run init_browser/driver.\n",
    "    browser = init_browser()\n",
    "\n",
    "\n",
    "    # Visit Nasa news url.\n",
    "    news_url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(news_url)\n",
    "\n",
    "\n",
    "    # HTML Object.\n",
    "    html = browser.html\n",
    "\n",
    "\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    news_soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "    # Retrieve the most recent article's title and paragraph.\n",
    "    # Store in news variables.\n",
    "    news_title = news_soup.find(\"div\", class_=\"content_title\").find('a').text\n",
    "    news_paragraph = news_soup.find(\"div\", class_=\"article_teaser_body\").get_text()\n",
    "\n",
    "\n",
    "    # Exit Browser.\n",
    "    browser.quit()\n",
    "\n",
    "\n",
    "    # Print Title and Text.\n",
    "    print(f'Title: {news_title}\\nText: {news_paragraph}')\n",
    "\n",
    "\n",
    "    \"\"\" JPL Mars Space Images - Featured Image \"\"\"\n",
    "\n",
    "\n",
    "    # Run init_browser/driver.\n",
    "    browser = init_browser()\n",
    "\n",
    "\n",
    "    # Visit the url for JPL Featured Space Image.\n",
    "    jpl_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(jpl_url)\n",
    "\n",
    "\n",
    "    # Select \"FULL IMAGE\".\n",
    "    browser.click_link_by_partial_text(\"FULL IMAGE\")\n",
    "\n",
    "\n",
    "    # Find \"more info\" for first image, set to variable, and command click.\n",
    "    browser.is_element_present_by_text(\"more info\", wait_time=1)\n",
    "    more_info_element = browser.find_link_by_partial_text(\"more info\")\n",
    "    more_info_element.click()\n",
    "\n",
    "\n",
    "    # HTML Object.\n",
    "    html = browser.html\n",
    "\n",
    "\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    image_soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "    # Scrape image URL.\n",
    "    image_url = image_soup.find(\"figure\", class_=\"lede\").a[\"href\"]\n",
    "\n",
    "\n",
    "    # Concatentate https://www.jpl.nasa.gov with image_url.\n",
    "    featured_image_url = f'https://www.jpl.nasa.gov{image_url}'\n",
    "\n",
    "\n",
    "    # Exit Browser.\n",
    "    browser.quit()\n",
    "\n",
    "\n",
    "    # Print Faetured Image URL.\n",
    "    print(featured_image_url)\n",
    "\n",
    "\n",
    "    \"\"\" Mars Weather \"\"\"\n",
    "\n",
    "\n",
    "    # Run init_browser/driver.\n",
    "    browser = init_browser()\n",
    "\n",
    "\n",
    "    # Visit the url for Mars Weather twitter account.\n",
    "    weather_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    browser.visit(weather_url)\n",
    "\n",
    "\n",
    "    # HTML Object.\n",
    "    html = browser.html\n",
    "\n",
    "\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    weather_soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "    # Retrieve ALL 'ol' tags and save to variable 'tweets'.\n",
    "    tweets = weather_soup.find_all('ol', class_='stream-items')\n",
    "    # Iterate through all 'tweets' and find text in 'p' tag.\n",
    "    # Break for most recent tweet if keyword 'InSight' in text.\n",
    "    # Otherwise move onto next tweet.\n",
    "    for tweet in tweets:\n",
    "        mars_weather = tweet.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "        if 'InSight' in tweet:\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "    # Exit Browser.\n",
    "    browser.quit()\n",
    "\n",
    "\n",
    "    # Remove 'anchor' tag text from \"mars_weather\" via split on 'pic'.\n",
    "    mars_weather = mars_weather.split('pic')[0]\n",
    "\n",
    "\n",
    "    # Replace '\\n' with ' '.\n",
    "    mars_weather = mars_weather.replace('\\n', ' ')\n",
    "\n",
    "\n",
    "    # Print most recent Mars Weather.\n",
    "    print(mars_weather)\n",
    "\n",
    "\n",
    "    \"\"\" Mars Facts \"\"\"\n",
    "\n",
    "\n",
    "    # URL for Mars Facts.\n",
    "    facts_url = \"https://space-facts.com/mars/\"\n",
    "\n",
    "\n",
    "    # Use Panda's `read_html` to parse the URL.\n",
    "    facts_tables = pd.read_html(facts_url)\n",
    "\n",
    "\n",
    "    # Required table stored in index \"1\".\n",
    "    # Save as DF.\n",
    "    df_mars_facts = facts_tables[1]\n",
    "\n",
    "\n",
    "    # Rename columns.\n",
    "    df_mars_facts.columns = ['Description', 'Value']\n",
    "\n",
    "\n",
    "    # Set index to 'Description'.\n",
    "    df_mars_facts.set_index('Description', inplace=True)\n",
    "\n",
    "\n",
    "    # # Convert DF to html and save in Resources Folder.\n",
    "    # df_mars_facts.to_html('Resources/mars_facts.html')\n",
    "\n",
    "\n",
    "    # Convert DF to HTML string.\n",
    "    mars_facts = df_mars_facts.to_html(header=True, index=True)\n",
    "\n",
    "\n",
    "    \"\"\" Mars Hemispheres \"\"\"\n",
    "\n",
    "\n",
    "    # Run init_browser/driver.\n",
    "    browser = init_browser()\n",
    "\n",
    "\n",
    "    # Visit the url for USGS Astrogeology.\n",
    "    astrogeo_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    browser.visit(astrogeo_url)\n",
    "\n",
    "\n",
    "    # HTML Object.\n",
    "    html = browser.html\n",
    "\n",
    "\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    astrogeo_soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "    # Store main URL in a variable so that 'href' can be appended to it after each iteration.\n",
    "    main_astrogeo_url = \"https://astrogeology.usgs.gov\"\n",
    "\n",
    "\n",
    "    # Each link is located in 'div' tag, class \"item\".\n",
    "    # Locate all 4 and store in variable.\n",
    "    hems_url = astrogeo_soup.find_all(\"div\", class_=\"item\")\n",
    "\n",
    "\n",
    "    # Create empty list for each Hemisphere URL.\n",
    "    hemis_url = []\n",
    "\n",
    "\n",
    "    for hem in hems_url:\n",
    "        hem_url = hem.find('a')['href']\n",
    "        hemis_url.append(hem_url)\n",
    "\n",
    "\n",
    "    browser.quit()\n",
    "\n",
    "\n",
    "    # Create list of dictionaries called hemisphere_image_urls.\n",
    "    # Iterate through all URLs saved in hemis_url.\n",
    "    # Concatenate each with the main_astrogeo_url.\n",
    "    # Confirm the concat worked properly: confirmed.\n",
    "    # Visit each URL.\n",
    "\n",
    "\n",
    "    hemisphere_image_urls = []\n",
    "    for hemi in hemis_url:\n",
    "        hem_astrogeo_url = main_astrogeo_url + hemi\n",
    "        print(hem_astrogeo_url)\n",
    "        \n",
    "        # Run init_browser/driver.\n",
    "        browser = init_browser()\n",
    "        browser.visit(hem_astrogeo_url)\n",
    "        \n",
    "        # HTML Object.\n",
    "        html = browser.html\n",
    "\n",
    "\n",
    "        # Parse HTML with Beautiful Soup\n",
    "        hemi_soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "        # Locate each title and save to raw_title, to be cleaned.\n",
    "        raw_title = hemi_soup.find(\"h2\", class_=\"title\").text\n",
    "        \n",
    "        # Remove ' Enhanced' tag text from each \"title\" via split on ' Enhanced'.\n",
    "        title = raw_title.split(' Enhanced')[0]\n",
    "        \n",
    "        # Locate each 'full.jpg' for all 4 Hemisphere URLs.\n",
    "        img_url = hemi_soup.find(\"li\").a['href']\n",
    "        \n",
    "        # Append both title and img_url to 'hemisphere_image_url'.\n",
    "        hemisphere_image_urls.append({'title': title, 'img_url': img_url})\n",
    "        \n",
    "        browser.quit()\n",
    "\n",
    "\n",
    "    print(hemisphere_image_urls)\n",
    "\n",
    "\n",
    "    \"\"\" Mars Data Dictionary - MongoDB \"\"\"\n",
    "\n",
    "\n",
    "    # Create empty dictionary for all Mars Data.\n",
    "    mars_data = {}\n",
    "\n",
    "\n",
    "    # Append news_title and news_paragraph to mars_data.\n",
    "    mars_data['news_title'] = news_title\n",
    "    mars_data['news_paragraph'] = news_paragraph\n",
    "\n",
    "\n",
    "    # Append featured_image_url to mars_data.\n",
    "    mars_data['featured_image_url'] = featured_image_url\n",
    "\n",
    "\n",
    "    # Append mars_weather to mars_data.\n",
    "    mars_data['mars_weather'] = mars_weather\n",
    "\n",
    "\n",
    "    # Append mars_facts to mars_data.\n",
    "    mars_data['mars_facts'] = mars_facts\n",
    "\n",
    "\n",
    "    # Append hemisphere_image_urls to mars_data.\n",
    "    mars_data['hemisphere_image_urls'] = hemisphere_image_urls\n",
    "\n",
    "\n",
    "    print(\"Scrape Complete!!!\")\n",
    "\n",
    "\n",
    "    return mars_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
